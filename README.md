# CNKI-Web
知网和web是利用爬虫和数据分析功能呢，对文献搜集，利用文献软件分析。

#KG
标准文献知识图谱构建

## 1 数据收集

采用爬虫方式，面向标准信息网和知网，收集标准文献信息，检索关键词为表5.1.2所示。在标准信息网中，文献包括“正在征求意见类”、“正在起草类”、“正在批准类”、“现行类”，其中，“正在征求意见类”可以直接下载PDF版本，因此，仅针对该类文献下载PDF。

## 2 PDF文献处理

采用pdfminer工具包，将PDF文献解码为word或者TXT格式，方便后续对文献内容进行处理。

## 3 数据处理

针对爬虫得到的文献基本信息和PDF解码得到的文献内容信息分别做进一步处理，处理手段为正则表达式，处理依据是标准文献要素类别。
进一步的，将知网信息、标准信息网信息、PDF文献信息做信息合并和清洗，得到较为干净的数据集。

## 4 KG可视化

利用neo4j和py2neo工具将整理的数据做可视化图谱展示，其中节点数量为1368，关系数量为2634，关系和节点与本章第一节有些出入，在实践中做了一些调整。
在KG中，关系类型包括：主管部门、发布单位、归口单位、执行单位、标准技术委员会、标准目录、标准范围、界定术语、相关图书、相近标准、起草人、起草单位；本体包括：主管部门、书籍名、发布单位、归口单位、执行单位、标准名、标准技术委员会、标准目录、标准范围、界定术语、起草人、起草单位；属性设计上，其中标准文献的属性包括：标准中文名、标准状态、标准类型、标准网址等等。
可视化展示结果如下（部分在PNG格式下，属性无法展示，因此，单列在下方）：



图5.2.1 关系类型为标准范围的可视化图

图5.2.2 关系类型为界定术语的可视化图





## 总结

## 5.3.1 知网爬取部分

第一，知网正常访问，3-5次，都能被认为是爬虫，正常检索都有可能检索不到文献，目前没有想到解决方式。
第二，知网在标准详情界面为动态加载数据，对于标准之间的关系，没有解析正确，没有爬取到相关的内容。

## 5.3.2 标准信息网爬取部分

第一，即使只是标准基本信息，但是加载网址不是直接的可视化的网址，需要找到真正的数据网址。
第二，跳转界面，第一步的跳转界面，即详情页面，包括了标准的基本信息，但是这个网址时java script中，不能通过xpath或者定位工具直接定位到，这里，我采用了re.(也明白了做事必有痕迹，爬虫就是找到真正的王者）
第三，是在在线预览界面，需要输入验证码，但是，当我直接捕获验证码网址，然后解析时，实际上又相当于刷新了一次界面，因此，解析出的验证码肯定不对。所以，后期，我直接将刷新的验证码在新标签页打开，然后通过driver截全屏的工具，截取图像，在通过裁剪图片，将验证码背景部分修剪掉。之后，在做验证码识别和输入。
第四，即使，可以预览全文，但在后台中，给出的图片源码下载后，得到的图像是乱的，像是小方块拼在一起的，这里应该是后端算法处理过。所以，不能直接捕获图片，目前打算采用截图，然后图像识别捕获内容。
第五，访问频繁，IP被禁，可以使用try except ,以及其他的一些技巧。比如，多尝试连接几次。

## 5.3.3 文献处理部分

utf-8-sig可以防止编译错误，比如，在编译器打开正常，但在记事本打开错误。

## 5.3.4 Neo4j配置部分

第一，Neo4j版本要和java版本匹配
第二，卸载neo4j要卸载完全，包括已建立过的数据库信息文件。

![在这里插入图片描述](https://img-blog.csdnimg.cn/7b05e5ebce6d4c22ab8d702965029b5f.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/a824ca378a4f4c988c5eb42d5456e899.png)
git地址：
